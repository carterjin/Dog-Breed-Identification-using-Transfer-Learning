{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Prediction using Transfer Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Earlier, in my [\"WeRateDogs Data Wrangling\" project](https://github.com/carterjin/Twitter-WeRateDogs-Data-Wrangling), we used some results provided by Udacity which take dog pictures and predicts its dog breeds. Now I would like to implement this myself. \n",
    "The data is downloaded from [Dog Breed Identification Kaggle Competition](https://www.kaggle.com/c/dog-breed-identification/data). The original data is from [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/). The data contains 10222 dog photos and labels indicating the breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten,\\\n",
    "GlobalAveragePooling2D\n",
    "from keras import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ''\n",
    "def read_img(img_id, train_or_test, size):\n",
    "    '''\n",
    "    Img_id: a string that is also the file name of the picture in train/test folder\n",
    "    train_or_test: a string indicating if the file is in train or test folder\n",
    "    size: a tuple ie (224,224) indicating the target size of the converted matrix\n",
    "    returns:\n",
    "    img: a matrix with shape depending on size, ie (224, 224, 3)\n",
    "    '''\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 is a popular deep residual learning framework for image classification. ImageNet is a set of pretrained weights that we can later use transfer training on. Let's first see how good is the prediction using ImageNet without any training. Considering time, I am only testing the first 20 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  finished\n",
      "20  finished\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights = 'imagenet')\n",
    "success = 0\n",
    "fail = 0\n",
    "i = 0\n",
    "for (img_id, breed) in labels.values:\n",
    "    img = read_img(img_id, 'train', (224,224))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis = 0))\n",
    "    preds = model.predict(x)\n",
    "    top_pred = decode_predictions(preds, top = 1)[0][0][1]\n",
    "    if (top_pred == breed):\n",
    "        success += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "    i += 1\n",
    "    if i % 10 == 0: print(i, ' finished')\n",
    "    if i == 20: break\n",
    "print(success/(success + fail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am reading all the image into a matrix X, which has shape (num_of_training_sample, 224, 224, 3). Also preprocess_input converts the values to be 0 centered, and converted from RGB coding to BGR coding, which the ImageNet weights used. img is expanded from (224,224,3) to (1,224,224,3) to fit in matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "bef = time()\n",
    "X = np.zeros((len(labels),224,224,3), dtype = 'float32')\n",
    "for i, img_id in enumerate(labels.id):\n",
    "    img = read_img(img_id, 'train', (224,224))\n",
    "    x = preprocess_input(np.expand_dims(img, axis = 0))\n",
    "    X[i] = x\n",
    "print(int(time() - bef),' second spent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = labels.breed.value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "I am importing the pretrained ResNet50 model without the classifier layers on the top, freeze this base model so it's not trainable, and then manually add the trainable classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kami\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(input_shape = (224,224,3),\n",
    "                      include_top = False,\n",
    "                      weights = 'imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the classifier layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = GlobalAveragePooling2D(input_shape = (7,7,2048))\n",
    "drop_layer = Dropout(0.5)\n",
    "prediction_layer = Dense(num_classes, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([base_model, \n",
    "                    global_average_layer, \n",
    "                    drop_layer, \n",
    "                    prediction_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 23,833,592\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "model.compile(optimizer = RMSprop(lr = learning_rate),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dummy variables for the breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(labels.breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(\n",
    "    X, y, test_size=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the data is barely handled with my laptop memory and takes a long time, so I am saving all the train, test, validation data in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#file = 'X_all'\n",
    "#joblib.dump([X_train,y_train, X_val, y_val, X_test, y_test], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "[X_train, y_train, X_val, y_val, X_test, y_test] = joblib.load('X_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using a data generator which also augments the data with rotation, shift, zoom, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "train_generator = datagen.flow(x = X_train, y = y_train)\n",
    "val_generator = datagen.flow(x = X_val, y = y_val)\n",
    "test_generator = datagen.flow(x = X_test, y = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "32/32 [==============================] - 228s 7s/step - loss: 5.7154 - accuracy: 0.0626\n",
      "Epoch 2/12\n",
      "32/32 [==============================] - 217s 7s/step - loss: 2.8692 - accuracy: 0.2923\n",
      "Epoch 3/12\n",
      "32/32 [==============================] - 216s 7s/step - loss: 1.7814 - accuracy: 0.5230\n",
      "Epoch 4/12\n",
      "32/32 [==============================] - 215s 7s/step - loss: 1.1836 - accuracy: 0.6618\n",
      "Epoch 5/12\n",
      "32/32 [==============================] - 215s 7s/step - loss: 0.9045 - accuracy: 0.7400\n",
      "Epoch 6/12\n",
      "32/32 [==============================] - 215s 7s/step - loss: 0.7608 - accuracy: 0.7840\n",
      "Epoch 7/12\n",
      "32/32 [==============================] - 215s 7s/step - loss: 0.6169 - accuracy: 0.8016\n",
      "Epoch 8/12\n",
      "32/32 [==============================] - 216s 7s/step - loss: 0.4969 - accuracy: 0.8495\n",
      "Epoch 9/12\n",
      "32/32 [==============================] - 215s 7s/step - loss: 0.4002 - accuracy: 0.8729\n",
      "Epoch 10/12\n",
      "32/32 [==============================] - 215s 7s/step - loss: 0.3276 - accuracy: 0.8886\n",
      "Epoch 11/12\n",
      "32/32 [==============================] - 217s 7s/step - loss: 0.3351 - accuracy: 0.9022\n",
      "Epoch 12/12\n",
      "32/32 [==============================] - 216s 7s/step - loss: 0.3410 - accuracy: 0.8866\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath = 'saved_model/best_val.hdf5')\n",
    "history = model.fit_generator(train_generator, validation_data = val_generator, epochs = 12, callbacks = [checkpointer],\n",
    "                             verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = 0\n",
    "fail = 0\n",
    "i = 1\n",
    "for (img_id, breed) in labels.values:\n",
    "    img = read_img(img_id, 'train', (224,224))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis = 0))\n",
    "    preds = model.predict(x)\n",
    "    top_pred = [1 if cl == max(preds[0]) else 0 for cl in preds[0]]\n",
    "    if (top_pred == list(y_train.loc[i])):\n",
    "        success += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "    i += 1\n",
    "    if i % 10 == 0: print(i, ' finished')\n",
    "    if i == 20: break\n",
    "print(success/(success + fail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254901960784313\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "fail = 0\n",
    "i = 0\n",
    "for i,x in enumerate(X_test):\n",
    "    feat = base_model.predict(np.expand_dims(x, axis = 0))\n",
    "    preds = model2.predict(feat)\n",
    "    top_pred = [1 if cl == max(preds[0]) else 0 for cl in preds[0]]\n",
    "    if (top_pred == list(y_test.iloc[i])):\n",
    "        success += 1\n",
    "    else:\n",
    "        fail +=1\n",
    "    if i == 50: break\n",
    "print(success/(success + fail))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file saved_model already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir saved_model\n",
    "model2.save('saved_model/bottleneck_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kami\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(pred, classes, top = 3):\n",
    "    # decode the prediction vector into a list of tuples consisting class name and probabilities, default top 3 is given\n",
    "    result = [('',0.0)] * len(classes)\n",
    "    for idx,prob in enumerate(pred[0]):\n",
    "        result[idx] = classes[idx], prob\n",
    "    result.sort(key = lambda x: x[1], reverse = True)\n",
    "    return result[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict(x)\n",
    "ans = decode_predictions(pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using bottleneck features\n",
    "\n",
    "One of the problem with the previous method is that when training, X_train needs to go through the ResNet base model (without classifier layers), and that makes the whole process taking around 10 hours to run on my laptop. While in fact, the base model parameters can't even be trained, so we can just train on the features we obtain from ResNet base models, which are called bottleneck features. This drastically decrease the computation time. However, the down side is we can't take advantage of image augmentation anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8049/8049 [==============================] - 1824s 227ms/step\n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train = base_model.predict(X_train, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 259s 7s/step\n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_val = base_model.predict_generator(val_generator, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bottleneck_features']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "file = 'bottleneck_features'\n",
    "joblib.dump([bottleneck_features_train,y_train, bottleneck_features_val, y_val],\n",
    "            file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(GlobalAveragePooling2D(input_shape = (7,7,2048)))\n",
    "model2.add(Dense(256, activation = 'relu'))\n",
    "model2.add(Dropout(0.6))\n",
    "model2.add(Dense(120, activation = 'softmax'))\n",
    "learning_rate= 0.001\n",
    "model2.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7244 samples, validate on 805 samples\n",
      "Epoch 1/100\n",
      "7244/7244 [==============================] - 6s 783us/step - loss: 3.9201 - accuracy: 0.1328 - val_loss: 2.1914 - val_accuracy: 0.5155\n",
      "Epoch 2/100\n",
      "7244/7244 [==============================] - 5s 710us/step - loss: 2.4424 - accuracy: 0.3545 - val_loss: 1.4119 - val_accuracy: 0.6149\n",
      "Epoch 3/100\n",
      "7244/7244 [==============================] - 5s 728us/step - loss: 1.8949 - accuracy: 0.4573 - val_loss: 1.1275 - val_accuracy: 0.6683\n",
      "Epoch 4/100\n",
      "7244/7244 [==============================] - 5s 731us/step - loss: 1.6478 - accuracy: 0.5195 - val_loss: 1.0073 - val_accuracy: 0.6907\n",
      "Epoch 5/100\n",
      "7244/7244 [==============================] - 5s 721us/step - loss: 1.4765 - accuracy: 0.5685 - val_loss: 0.9715 - val_accuracy: 0.6981\n",
      "Epoch 6/100\n",
      "7244/7244 [==============================] - 5s 712us/step - loss: 1.3536 - accuracy: 0.5853 - val_loss: 0.9544 - val_accuracy: 0.6994\n",
      "Epoch 7/100\n",
      "7244/7244 [==============================] - 5s 743us/step - loss: 1.2664 - accuracy: 0.6201 - val_loss: 0.9092 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "7244/7244 [==============================] - 5s 709us/step - loss: 1.1974 - accuracy: 0.6305 - val_loss: 0.9200 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "7244/7244 [==============================] - 5s 712us/step - loss: 1.1508 - accuracy: 0.6473 - val_loss: 0.8864 - val_accuracy: 0.7242\n",
      "Epoch 10/100\n",
      "7244/7244 [==============================] - 5s 710us/step - loss: 1.1291 - accuracy: 0.6517 - val_loss: 0.9389 - val_accuracy: 0.7081\n",
      "Epoch 11/100\n",
      "7244/7244 [==============================] - 5s 706us/step - loss: 1.0360 - accuracy: 0.6657 - val_loss: 0.9067 - val_accuracy: 0.7068\n",
      "Epoch 12/100\n",
      "7244/7244 [==============================] - 5s 715us/step - loss: 1.0201 - accuracy: 0.6773 - val_loss: 0.9061 - val_accuracy: 0.7106\n",
      "Epoch 13/100\n",
      "7244/7244 [==============================] - 6s 820us/step - loss: 0.9548 - accuracy: 0.6877 - val_loss: 0.9159 - val_accuracy: 0.7205\n",
      "Epoch 14/100\n",
      "7244/7244 [==============================] - 6s 792us/step - loss: 0.9513 - accuracy: 0.6949 - val_loss: 0.9046 - val_accuracy: 0.7056\n",
      "Epoch 15/100\n",
      "7244/7244 [==============================] - 5s 728us/step - loss: 0.9265 - accuracy: 0.6944 - val_loss: 0.8967 - val_accuracy: 0.7280\n",
      "Epoch 16/100\n",
      "7244/7244 [==============================] - 5s 707us/step - loss: 0.8854 - accuracy: 0.7091 - val_loss: 0.9065 - val_accuracy: 0.7317\n",
      "Epoch 17/100\n",
      "7244/7244 [==============================] - 5s 715us/step - loss: 0.8841 - accuracy: 0.7036 - val_loss: 0.9199 - val_accuracy: 0.7255\n",
      "Epoch 18/100\n",
      "7244/7244 [==============================] - 6s 761us/step - loss: 0.8529 - accuracy: 0.7199 - val_loss: 0.9367 - val_accuracy: 0.7168\n",
      "Epoch 19/100\n",
      "7244/7244 [==============================] - 5s 699us/step - loss: 0.8175 - accuracy: 0.7333 - val_loss: 0.9123 - val_accuracy: 0.7242\n",
      "Epoch 20/100\n",
      "7244/7244 [==============================] - 5s 693us/step - loss: 0.7966 - accuracy: 0.7325 - val_loss: 0.9347 - val_accuracy: 0.7143\n",
      "Epoch 21/100\n",
      "7244/7244 [==============================] - 5s 695us/step - loss: 0.7752 - accuracy: 0.7421 - val_loss: 0.9301 - val_accuracy: 0.7155\n",
      "Epoch 22/100\n",
      "7244/7244 [==============================] - 5s 703us/step - loss: 0.7681 - accuracy: 0.7420 - val_loss: 0.9482 - val_accuracy: 0.7217\n",
      "Epoch 23/100\n",
      "7244/7244 [==============================] - 5s 692us/step - loss: 0.7239 - accuracy: 0.7572 - val_loss: 0.9826 - val_accuracy: 0.7081\n",
      "Epoch 24/100\n",
      "7244/7244 [==============================] - 6s 844us/step - loss: 0.7222 - accuracy: 0.7533 - val_loss: 1.0030 - val_accuracy: 0.7130\n",
      "Epoch 25/100\n",
      "7244/7244 [==============================] - 5s 716us/step - loss: 0.7044 - accuracy: 0.7561 - val_loss: 0.9650 - val_accuracy: 0.7193\n",
      "Epoch 26/100\n",
      "7244/7244 [==============================] - 5s 692us/step - loss: 0.6708 - accuracy: 0.7726 - val_loss: 1.0069 - val_accuracy: 0.7118\n",
      "Epoch 27/100\n",
      "7244/7244 [==============================] - 5s 693us/step - loss: 0.6839 - accuracy: 0.7670 - val_loss: 0.9846 - val_accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "7244/7244 [==============================] - 5s 694us/step - loss: 0.6624 - accuracy: 0.7721 - val_loss: 0.9902 - val_accuracy: 0.7106\n",
      "Epoch 29/100\n",
      "7244/7244 [==============================] - 5s 685us/step - loss: 0.6705 - accuracy: 0.7708 - val_loss: 1.0342 - val_accuracy: 0.7081\n",
      "Epoch 30/100\n",
      "7244/7244 [==============================] - 6s 770us/step - loss: 0.6413 - accuracy: 0.7819 - val_loss: 1.0159 - val_accuracy: 0.7130\n",
      "Epoch 31/100\n",
      "7244/7244 [==============================] - 5s 699us/step - loss: 0.6199 - accuracy: 0.7906 - val_loss: 1.0028 - val_accuracy: 0.7180\n",
      "Epoch 32/100\n",
      "7244/7244 [==============================] - 6s 856us/step - loss: 0.5956 - accuracy: 0.7939 - val_loss: 1.0566 - val_accuracy: 0.7242\n",
      "Epoch 33/100\n",
      "7244/7244 [==============================] - 6s 774us/step - loss: 0.6258 - accuracy: 0.7877 - val_loss: 1.0575 - val_accuracy: 0.7143\n",
      "Epoch 34/100\n",
      "7244/7244 [==============================] - 5s 716us/step - loss: 0.6014 - accuracy: 0.7940 - val_loss: 1.0875 - val_accuracy: 0.7168\n",
      "Epoch 35/100\n",
      "7244/7244 [==============================] - 6s 777us/step - loss: 0.5944 - accuracy: 0.8002 - val_loss: 1.0809 - val_accuracy: 0.7155\n",
      "Epoch 36/100\n",
      "7244/7244 [==============================] - 5s 733us/step - loss: 0.5806 - accuracy: 0.7994 - val_loss: 1.1083 - val_accuracy: 0.7242\n",
      "Epoch 37/100\n",
      "7244/7244 [==============================] - 5s 744us/step - loss: 0.5938 - accuracy: 0.7913 - val_loss: 1.0433 - val_accuracy: 0.7267\n",
      "Epoch 38/100\n",
      "7244/7244 [==============================] - 6s 772us/step - loss: 0.5643 - accuracy: 0.8074 - val_loss: 1.0602 - val_accuracy: 0.7217\n",
      "Epoch 39/100\n",
      "7244/7244 [==============================] - 5s 746us/step - loss: 0.5628 - accuracy: 0.8027 - val_loss: 1.1500 - val_accuracy: 0.7081\n",
      "Epoch 40/100\n",
      "7244/7244 [==============================] - 5s 709us/step - loss: 0.5566 - accuracy: 0.8023 - val_loss: 1.0640 - val_accuracy: 0.7304\n",
      "Epoch 41/100\n",
      "7244/7244 [==============================] - 5s 734us/step - loss: 0.5361 - accuracy: 0.8192 - val_loss: 1.1481 - val_accuracy: 0.7255\n",
      "Epoch 42/100\n",
      "7244/7244 [==============================] - 5s 704us/step - loss: 0.5340 - accuracy: 0.8100 - val_loss: 1.0892 - val_accuracy: 0.7280\n",
      "Epoch 43/100\n",
      "7244/7244 [==============================] - 5s 701us/step - loss: 0.5253 - accuracy: 0.8185 - val_loss: 1.1585 - val_accuracy: 0.7267\n",
      "Epoch 44/100\n",
      "7244/7244 [==============================] - 5s 682us/step - loss: 0.5252 - accuracy: 0.8227 - val_loss: 1.1061 - val_accuracy: 0.7155\n",
      "Epoch 45/100\n",
      "7244/7244 [==============================] - 5s 703us/step - loss: 0.5304 - accuracy: 0.8146 - val_loss: 1.1512 - val_accuracy: 0.7217\n",
      "Epoch 46/100\n",
      "7244/7244 [==============================] - 5s 714us/step - loss: 0.5130 - accuracy: 0.8205 - val_loss: 1.1724 - val_accuracy: 0.7168\n",
      "Epoch 47/100\n",
      "7244/7244 [==============================] - 5s 706us/step - loss: 0.4973 - accuracy: 0.8212 - val_loss: 1.2244 - val_accuracy: 0.7205\n",
      "Epoch 48/100\n",
      "7244/7244 [==============================] - 5s 684us/step - loss: 0.5317 - accuracy: 0.8125 - val_loss: 1.1413 - val_accuracy: 0.7217\n",
      "Epoch 49/100\n",
      "7244/7244 [==============================] - 5s 686us/step - loss: 0.4948 - accuracy: 0.8291 - val_loss: 1.1664 - val_accuracy: 0.7205\n",
      "Epoch 50/100\n",
      "7244/7244 [==============================] - 5s 688us/step - loss: 0.4715 - accuracy: 0.8356 - val_loss: 1.3078 - val_accuracy: 0.7068\n",
      "Epoch 51/100\n",
      "7244/7244 [==============================] - 5s 691us/step - loss: 0.4912 - accuracy: 0.8281 - val_loss: 1.2092 - val_accuracy: 0.7205\n",
      "Epoch 52/100\n",
      "7244/7244 [==============================] - 5s 687us/step - loss: 0.4705 - accuracy: 0.8350 - val_loss: 1.1713 - val_accuracy: 0.7354\n",
      "Epoch 53/100\n",
      "7244/7244 [==============================] - 5s 722us/step - loss: 0.4915 - accuracy: 0.8273 - val_loss: 1.2164 - val_accuracy: 0.7255\n",
      "Epoch 54/100\n",
      "7244/7244 [==============================] - 5s 684us/step - loss: 0.4816 - accuracy: 0.8331 - val_loss: 1.2817 - val_accuracy: 0.7242\n",
      "Epoch 55/100\n",
      "7244/7244 [==============================] - 5s 673us/step - loss: 0.4661 - accuracy: 0.8396 - val_loss: 1.2836 - val_accuracy: 0.7217\n",
      "Epoch 56/100\n",
      "7244/7244 [==============================] - 5s 698us/step - loss: 0.4787 - accuracy: 0.8306 - val_loss: 1.3716 - val_accuracy: 0.7168\n",
      "Epoch 57/100\n",
      "7244/7244 [==============================] - 5s 689us/step - loss: 0.4709 - accuracy: 0.8332 - val_loss: 1.2892 - val_accuracy: 0.7205\n",
      "Epoch 58/100\n",
      "7244/7244 [==============================] - 5s 696us/step - loss: 0.4537 - accuracy: 0.8437 - val_loss: 1.3141 - val_accuracy: 0.7255\n",
      "Epoch 59/100\n",
      "7244/7244 [==============================] - 5s 726us/step - loss: 0.4798 - accuracy: 0.8356 - val_loss: 1.2840 - val_accuracy: 0.7304\n",
      "Epoch 60/100\n",
      "7244/7244 [==============================] - 5s 706us/step - loss: 0.4560 - accuracy: 0.8414 - val_loss: 1.3316 - val_accuracy: 0.7130\n",
      "Epoch 61/100\n",
      "7244/7244 [==============================] - 5s 729us/step - loss: 0.4495 - accuracy: 0.8437 - val_loss: 1.3865 - val_accuracy: 0.7155\n",
      "Epoch 62/100\n",
      "7244/7244 [==============================] - 5s 706us/step - loss: 0.4436 - accuracy: 0.8439 - val_loss: 1.3675 - val_accuracy: 0.6944\n",
      "Epoch 63/100\n",
      "7244/7244 [==============================] - 5s 704us/step - loss: 0.4227 - accuracy: 0.8538 - val_loss: 1.3606 - val_accuracy: 0.7081\n",
      "Epoch 64/100\n",
      "7244/7244 [==============================] - 5s 725us/step - loss: 0.4288 - accuracy: 0.8466 - val_loss: 1.3281 - val_accuracy: 0.7255\n",
      "Epoch 65/100\n",
      "7244/7244 [==============================] - 5s 704us/step - loss: 0.4422 - accuracy: 0.8484 - val_loss: 1.3200 - val_accuracy: 0.7168\n",
      "Epoch 66/100\n",
      "7244/7244 [==============================] - 5s 707us/step - loss: 0.4207 - accuracy: 0.8542 - val_loss: 1.3974 - val_accuracy: 0.7267\n",
      "Epoch 67/100\n",
      "7244/7244 [==============================] - 5s 706us/step - loss: 0.4200 - accuracy: 0.8549 - val_loss: 1.4107 - val_accuracy: 0.7267\n",
      "Epoch 68/100\n",
      "7244/7244 [==============================] - 5s 697us/step - loss: 0.4152 - accuracy: 0.8591 - val_loss: 1.3354 - val_accuracy: 0.7230\n",
      "Epoch 69/100\n",
      "7244/7244 [==============================] - 5s 698us/step - loss: 0.4272 - accuracy: 0.8539 - val_loss: 1.4161 - val_accuracy: 0.7193\n",
      "Epoch 70/100\n",
      "7244/7244 [==============================] - 5s 715us/step - loss: 0.4181 - accuracy: 0.8531 - val_loss: 1.4069 - val_accuracy: 0.7143\n",
      "Epoch 71/100\n",
      "7244/7244 [==============================] - 5s 719us/step - loss: 0.4317 - accuracy: 0.8508 - val_loss: 1.4189 - val_accuracy: 0.7093\n",
      "Epoch 72/100\n",
      "7244/7244 [==============================] - 5s 707us/step - loss: 0.4113 - accuracy: 0.8545 - val_loss: 1.3712 - val_accuracy: 0.7280\n",
      "Epoch 73/100\n",
      "7244/7244 [==============================] - 5s 697us/step - loss: 0.4249 - accuracy: 0.8530 - val_loss: 1.4850 - val_accuracy: 0.7180\n",
      "Epoch 74/100\n",
      "7244/7244 [==============================] - 5s 711us/step - loss: 0.3905 - accuracy: 0.8603 - val_loss: 1.4190 - val_accuracy: 0.7304\n",
      "Epoch 75/100\n",
      "7244/7244 [==============================] - 5s 711us/step - loss: 0.4012 - accuracy: 0.8617 - val_loss: 1.4027 - val_accuracy: 0.7217\n",
      "Epoch 76/100\n",
      "7244/7244 [==============================] - 5s 730us/step - loss: 0.3853 - accuracy: 0.8596 - val_loss: 1.5067 - val_accuracy: 0.7118\n",
      "Epoch 77/100\n",
      "7244/7244 [==============================] - 5s 705us/step - loss: 0.4234 - accuracy: 0.8516 - val_loss: 1.3730 - val_accuracy: 0.7404\n",
      "Epoch 78/100\n",
      "7244/7244 [==============================] - 5s 702us/step - loss: 0.3885 - accuracy: 0.8668 - val_loss: 1.4142 - val_accuracy: 0.7267\n",
      "Epoch 79/100\n",
      "7244/7244 [==============================] - 5s 702us/step - loss: 0.4116 - accuracy: 0.8593 - val_loss: 1.4597 - val_accuracy: 0.7031\n",
      "Epoch 80/100\n",
      "7244/7244 [==============================] - 5s 708us/step - loss: 0.4008 - accuracy: 0.8568 - val_loss: 1.4092 - val_accuracy: 0.7242\n",
      "Epoch 81/100\n",
      "7244/7244 [==============================] - 5s 708us/step - loss: 0.4205 - accuracy: 0.8530 - val_loss: 1.3743 - val_accuracy: 0.7217\n",
      "Epoch 82/100\n",
      "7244/7244 [==============================] - 5s 730us/step - loss: 0.3722 - accuracy: 0.8679 - val_loss: 1.4923 - val_accuracy: 0.7217\n",
      "Epoch 83/100\n",
      "7244/7244 [==============================] - 5s 713us/step - loss: 0.3813 - accuracy: 0.8669 - val_loss: 1.5165 - val_accuracy: 0.7180\n",
      "Epoch 84/100\n",
      "7244/7244 [==============================] - 5s 756us/step - loss: 0.3748 - accuracy: 0.8702 - val_loss: 1.4233 - val_accuracy: 0.7242\n",
      "Epoch 85/100\n",
      "7244/7244 [==============================] - 5s 741us/step - loss: 0.3816 - accuracy: 0.8617 - val_loss: 1.4357 - val_accuracy: 0.7230\n",
      "Epoch 86/100\n",
      "7244/7244 [==============================] - 5s 732us/step - loss: 0.4033 - accuracy: 0.8586 - val_loss: 1.5567 - val_accuracy: 0.7093\n",
      "Epoch 87/100\n",
      "7244/7244 [==============================] - 5s 705us/step - loss: 0.3681 - accuracy: 0.8748 - val_loss: 1.5687 - val_accuracy: 0.7354\n",
      "Epoch 88/100\n",
      "7244/7244 [==============================] - 5s 718us/step - loss: 0.3925 - accuracy: 0.8658 - val_loss: 1.5956 - val_accuracy: 0.7342\n",
      "Epoch 89/100\n",
      "7244/7244 [==============================] - 5s 705us/step - loss: 0.3690 - accuracy: 0.8698 - val_loss: 1.5573 - val_accuracy: 0.7292\n",
      "Epoch 90/100\n",
      "7244/7244 [==============================] - 5s 733us/step - loss: 0.3645 - accuracy: 0.8686 - val_loss: 1.6628 - val_accuracy: 0.7143\n",
      "Epoch 91/100\n",
      "7244/7244 [==============================] - 5s 730us/step - loss: 0.3863 - accuracy: 0.8679 - val_loss: 1.6574 - val_accuracy: 0.7217\n",
      "Epoch 92/100\n",
      "7244/7244 [==============================] - 5s 705us/step - loss: 0.3645 - accuracy: 0.8708 - val_loss: 1.6729 - val_accuracy: 0.7031\n",
      "Epoch 93/100\n",
      "7244/7244 [==============================] - 5s 708us/step - loss: 0.3687 - accuracy: 0.8694 - val_loss: 1.5509 - val_accuracy: 0.7242\n",
      "Epoch 94/100\n",
      "7244/7244 [==============================] - 5s 700us/step - loss: 0.3475 - accuracy: 0.8747 - val_loss: 1.6121 - val_accuracy: 0.7031\n",
      "Epoch 95/100\n",
      "7244/7244 [==============================] - 5s 700us/step - loss: 0.3730 - accuracy: 0.8709 - val_loss: 1.5582 - val_accuracy: 0.7230\n",
      "Epoch 96/100\n",
      "7244/7244 [==============================] - 5s 755us/step - loss: 0.3809 - accuracy: 0.8731 - val_loss: 1.5836 - val_accuracy: 0.7155\n",
      "Epoch 97/100\n",
      "7244/7244 [==============================] - 5s 696us/step - loss: 0.3669 - accuracy: 0.8711 - val_loss: 1.6240 - val_accuracy: 0.7205\n",
      "Epoch 98/100\n",
      "7244/7244 [==============================] - 5s 680us/step - loss: 0.3965 - accuracy: 0.8655 - val_loss: 1.6395 - val_accuracy: 0.7267\n",
      "Epoch 99/100\n",
      "7244/7244 [==============================] - 5s 698us/step - loss: 0.3551 - accuracy: 0.8770 - val_loss: 1.6904 - val_accuracy: 0.6969\n",
      "Epoch 100/100\n",
      "7244/7244 [==============================] - 5s 700us/step - loss: 0.3609 - accuracy: 0.8798 - val_loss: 1.7663 - val_accuracy: 0.7130\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(bottleneck_features_train, y_train, validation_split = 0.1, epochs = 100,\n",
    "                             verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, earlier it took about 30 minute to run each epoch, now it took only a few seconds.\n",
    "This method gave us 72.5% accuracy for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
